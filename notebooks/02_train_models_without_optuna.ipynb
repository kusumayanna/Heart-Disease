{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Heart Disease Classification - Training Without Optuna\n",
        "\n",
        "This notebook trains 8 models (4 algorithms √ó 2 PCA conditions) using default hyperparameters:\n",
        "\n",
        "**Algorithms:** Logistic Regression, Random Forest, SVM, XGBoost  \n",
        "**Conditions:** With PCA, Without PCA  \n",
        "**Metric:** F1-Score (for classification)\n",
        "\n",
        "## Experiment Matrix (8 total experiments)\n",
        "\n",
        "| Algorithm | No PCA | With PCA |\n",
        "|-----------|--------|----------|\n",
        "| Logistic Regression | ‚úì | ‚úì |\n",
        "| Random Forest | ‚úì | ‚úì |\n",
        "| SVM | ‚úì | ‚úì |\n",
        "| XGBoost | ‚úì | ‚úì |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base folder: /Users/kusumareddy/python_final\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "import mlflow\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "# Set base folder\n",
        "base_folder = Path(os.getcwd()).parent\n",
        "sys.path.insert(0, str(base_folder))\n",
        "\n",
        "print(f\"Base folder: {base_folder}\")\n",
        "start_time = time.monotonic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded environment from /Users/kusumareddy/python_final/.env\n",
            "‚úì MLflow tracking URI: https://dagshub.com/kusumayanna9/python_final.mlflow\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables for MLflow/Dagshub\n",
        "env_path = base_folder /  \".env\"\n",
        "if env_path.exists():\n",
        "    load_dotenv(env_path)\n",
        "    print(f\"‚úì Loaded environment from {env_path}\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  No .env file found at {env_path}\")\n",
        "    print(\"   Create notebooks/.env with your Dagshub credentials for experiment tracking\")\n",
        "\n",
        "# Set up MLflow\n",
        "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"\")\n",
        "MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\", \"\")\n",
        "MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\", \"\")\n",
        "\n",
        "if MLFLOW_TRACKING_USERNAME:\n",
        "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = MLFLOW_TRACKING_USERNAME\n",
        "if MLFLOW_TRACKING_PASSWORD:\n",
        "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = MLFLOW_TRACKING_PASSWORD\n",
        "\n",
        "if MLFLOW_TRACKING_URI:\n",
        "    mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "    print(f\"‚úì MLflow tracking URI: {MLFLOW_TRACKING_URI}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No MLflow tracking URI configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data from SQLite Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/db_utils.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
            "  df = pd.read_sql_query(query, conn)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Loaded 1025 patients from PostgreSQL database\n",
            "  Target distribution: {1: 526, 0: 499}\n",
            "  Features: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>212</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>168</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>203</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>155</td>\n",
              "      <td>1</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>145</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>125</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>61</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>148</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>161</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>294</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>106</td>\n",
              "      <td>0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   patient_id  age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
              "0           0   52    1   0       125   212    0        1      168      0   \n",
              "1           1   53    1   0       140   203    1        0      155      1   \n",
              "2           2   70    1   0       145   174    0        1      125      1   \n",
              "3           3   61    1   0       148   203    0        1      161      0   \n",
              "4           4   62    0   0       138   294    1        1      106      0   \n",
              "\n",
              "   oldpeak  slope  ca  thal  target  \n",
              "0      1.0      2   2     3       0  \n",
              "1      3.1      0   0     3       0  \n",
              "2      2.6      0   0     3       0  \n",
              "3      0.0      2   1     3       0  \n",
              "4      1.9      1   3     2       0  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load data from PostgreSQL database using utilities\n",
        "from db_utils import load_heart_data\n",
        "\n",
        "heart_data = load_heart_data()\n",
        "print(f\"  Target distribution: {heart_data['target'].value_counts().to_dict()}\")\n",
        "print(f\"  Features: {list(heart_data.columns[1:-1])}\")\n",
        "heart_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Data and Setup Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Train size: 820, Test size: 205\n",
            "  Train target distribution: {1: 421, 0: 399}\n",
            "  Test target distribution: {1: 105, 0: 100}\n"
          ]
        }
      ],
      "source": [
        "# Split data\n",
        "X = heart_data.drop(['patient_id', 'target'], axis=1)\n",
        "y = heart_data['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"‚úì Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "print(f\"  Train target distribution: {y_train.value_counts().to_dict()}\")\n",
        "print(f\"  Test target distribution: {y_test.value_counts().to_dict()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì Preprocessing pipeline created\n",
            "  Expected features: ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n"
          ]
        }
      ],
      "source": [
        "# Import preprocessing pipeline\n",
        "from classification_pipeline import build_preprocessing, FEATURE_NAMES\n",
        "\n",
        "preprocessing = build_preprocessing()\n",
        "print(f\"‚úì Preprocessing pipeline created\")\n",
        "print(f\"  Expected features: {FEATURE_NAMES}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1-4: Models WITHOUT PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING 4 MODELS WITHOUT PCA (DEFAULT HYPERPARAMETERS)\n",
            "================================================================================\n",
            "\n",
            "üîç Training LOGISTIC_NO_OPTUNA...\n",
            "  CV F1: 0.8548 (¬±0.0396)\n",
            "  Test F1: 0.8312, Test Accuracy: 0.8098\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/logistic_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:49:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run logistic_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/820a7bbde1f44a53924094d486d6b7c1\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n",
            "\n",
            "üîç Training RANDOMFOREST_NO_OPTUNA...\n",
            "  CV F1: 0.9822 (¬±0.0374)\n",
            "  Test F1: 1.0000, Test Accuracy: 1.0000\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/randomforest_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:50:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run randomforest_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/099504031b144dfeb52d82c9c38f5c68\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n",
            "\n",
            "üîç Training SVM_NO_OPTUNA...\n",
            "  CV F1: 0.9166 (¬±0.0367)\n",
            "  Test F1: 0.9296, Test Accuracy: 0.9268\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/svm_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:50:37 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run svm_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/392b9e9c4e554df9985efa987e7755a2\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n",
            "\n",
            "üîç Training XGBOOST_NO_OPTUNA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:50:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:50:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  CV F1: 0.9859 (¬±0.0189)\n",
            "  Test F1: 1.0000, Test Accuracy: 1.0000\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/xgboost_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:51:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run xgboost_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/dd372c0fe6bf45658c343329df8c3157\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING 4 MODELS WITHOUT PCA (DEFAULT HYPERPARAMETERS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Define models with default hyperparameters\n",
        "models_no_pca = {\n",
        "    \"logistic_no_optuna\": LogisticRegression(\n",
        "        random_state=42, max_iter=1000, solver='lbfgs'\n",
        "    ),\n",
        "    \"randomforest_no_optuna\": RandomForestClassifier(\n",
        "        random_state=42, n_estimators=100, max_depth=10, n_jobs=-1\n",
        "    ),\n",
        "    \"svm_no_optuna\": SVC(\n",
        "        random_state=42, kernel='rbf', probability=True\n",
        "    ),\n",
        "    \"xgboost_no_optuna\": XGBClassifier(\n",
        "        objective=\"binary:logistic\", random_state=42, n_estimators=100,\n",
        "        learning_rate=0.1, max_depth=6, use_label_encoder=False,\n",
        "        eval_metric='logloss', n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "results_no_pca = {}\n",
        "\n",
        "for name, model in models_no_pca.items():\n",
        "    print(f\"\\nüîç Training {name.upper()}...\")\n",
        "    \n",
        "    # Create pipeline\n",
        "    pipeline = make_pipeline(preprocessing, model)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=\"f1\")\n",
        "    cv_f1 = cv_scores.mean()\n",
        "    \n",
        "    # Train on full training set\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # Test predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    test_f1 = f1_score(y_test, y_pred)\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    print(f\"  CV F1: {cv_f1:.4f} (¬±{cv_scores.std()*2:.4f})\")\n",
        "    print(f\"  Test F1: {test_f1:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "    \n",
        "    # Store results\n",
        "    results_no_pca[name] = {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"cv_f1\": cv_f1,\n",
        "        \"test_f1\": test_f1,\n",
        "        \"test_acc\": test_acc\n",
        "    }\n",
        "    \n",
        "    # Save model\n",
        "    models_dir = base_folder / \"models\"\n",
        "    models_dir.mkdir(exist_ok=True)\n",
        "    model_path = models_dir / f\"{name}.pkl\"\n",
        "    joblib.dump(pipeline, model_path)\n",
        "    print(f\"  ‚úì Model saved to {model_path}\")\n",
        "    \n",
        "    # Log to MLflow if configured\n",
        "    if MLFLOW_TRACKING_URI:\n",
        "        with mlflow.start_run(run_name=name):\n",
        "            mlflow.log_param(\"model\", name.split(\"_\")[0])\n",
        "            mlflow.log_param(\"uses_pca\", False)\n",
        "            mlflow.log_param(\"uses_optuna\", False)\n",
        "            mlflow.log_metric(\"cv_f1\", cv_f1)\n",
        "            mlflow.log_metric(\"test_f1\", test_f1)\n",
        "            mlflow.log_metric(\"test_accuracy\", test_acc)\n",
        "            \n",
        "            signature = infer_signature(X_train, pipeline.predict(X_train))\n",
        "            mlflow.sklearn.log_model(pipeline, \"model\", signature=signature)\n",
        "        print(f\"  ‚úì Logged to MLflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 5-8: Models WITH PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING 4 MODELS WITH PCA (DEFAULT HYPERPARAMETERS)\n",
            "================================================================================\n",
            "\n",
            "üîç Training LOGISTIC_WITH_PCA_NO_OPTUNA...\n",
            "  PCA: 12 components, 0.971 variance explained\n",
            "  CV F1: 0.8524 (¬±0.0435)\n",
            "  Test F1: 0.8312, Test Accuracy: 0.8098\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/logistic_with_pca_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:51:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run logistic_with_pca_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/38a343915c0b4d56b994a693e702c7d8\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n",
            "\n",
            "üîç Training RANDOMFOREST_WITH_PCA_NO_OPTUNA...\n",
            "  PCA: 12 components, 0.971 variance explained\n",
            "  CV F1: 0.9811 (¬±0.0336)\n",
            "  Test F1: 1.0000, Test Accuracy: 1.0000\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/randomforest_with_pca_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:51:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run randomforest_with_pca_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/250f2144cee14d1ea52d2770531d3d48\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n",
            "\n",
            "üîç Training SVM_WITH_PCA_NO_OPTUNA...\n",
            "  PCA: 12 components, 0.971 variance explained\n",
            "  CV F1: 0.9121 (¬±0.0386)\n",
            "  Test F1: 0.9252, Test Accuracy: 0.9220\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/svm_with_pca_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:52:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run svm_with_pca_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/45ec8bbaf73a49eda5767b23df0fc9e7\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n",
            "\n",
            "üîç Training XGBOOST_WITH_PCA_NO_OPTUNA...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:52:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:52:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:52:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:52:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:52:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/xgboost/training.py:199: UserWarning: [07:52:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  PCA: 12 components, 0.971 variance explained\n",
            "  CV F1: 0.9822 (¬±0.0333)\n",
            "  Test F1: 1.0000, Test Accuracy: 1.0000\n",
            "  ‚úì Model saved to /Users/kusumareddy/python_final/models/xgboost_with_pca_no_optuna.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/kusumareddy/python_final/venv/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
            "  warnings.warn(\n",
            "2025/12/19 07:52:45 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run xgboost_with_pca_no_optuna at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0/runs/7497901befe34759b2644ac622fe31fb\n",
            "üß™ View experiment at: https://dagshub.com/kusumayanna9/python_final.mlflow/#/experiments/0\n",
            "  ‚úì Logged to MLflow\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING 4 MODELS WITH PCA (DEFAULT HYPERPARAMETERS)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Define models with PCA (95% variance retention)\n",
        "models_with_pca = {\n",
        "    \"logistic_with_pca_no_optuna\": LogisticRegression(\n",
        "        random_state=42, max_iter=1000, solver='lbfgs'\n",
        "    ),\n",
        "    \"randomforest_with_pca_no_optuna\": RandomForestClassifier(\n",
        "        random_state=42, n_estimators=100, max_depth=10, n_jobs=-1\n",
        "    ),\n",
        "    \"svm_with_pca_no_optuna\": SVC(\n",
        "        random_state=42, kernel='rbf', probability=True\n",
        "    ),\n",
        "    \"xgboost_with_pca_no_optuna\": XGBClassifier(\n",
        "        objective=\"binary:logistic\", random_state=42, n_estimators=100,\n",
        "        learning_rate=0.1, max_depth=6, use_label_encoder=False,\n",
        "        eval_metric='logloss', n_jobs=-1\n",
        "    )\n",
        "}\n",
        "\n",
        "results_with_pca = {}\n",
        "pca_components = 0.95  # Retain 95% of variance\n",
        "\n",
        "for name, model in models_with_pca.items():\n",
        "    print(f\"\\nüîç Training {name.upper()}...\")\n",
        "    \n",
        "    # Create pipeline with PCA\n",
        "    pipeline = make_pipeline(\n",
        "        preprocessing,\n",
        "        PCA(n_components=pca_components),\n",
        "        model\n",
        "    )\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=\"f1\")\n",
        "    cv_f1 = cv_scores.mean()\n",
        "    \n",
        "    # Train on full training set\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # Check PCA components\n",
        "    pca_step = pipeline.named_steps['pca']\n",
        "    n_components_used = pca_step.n_components_\n",
        "    explained_variance = pca_step.explained_variance_ratio_.sum()\n",
        "    \n",
        "    # Test predictions\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    test_f1 = f1_score(y_test, y_pred)\n",
        "    test_acc = accuracy_score(y_test, y_pred)\n",
        "    \n",
        "    print(f\"  PCA: {n_components_used} components, {explained_variance:.3f} variance explained\")\n",
        "    print(f\"  CV F1: {cv_f1:.4f} (¬±{cv_scores.std()*2:.4f})\")\n",
        "    print(f\"  Test F1: {test_f1:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "    \n",
        "    # Store results\n",
        "    results_with_pca[name] = {\n",
        "        \"pipeline\": pipeline,\n",
        "        \"cv_f1\": cv_f1,\n",
        "        \"test_f1\": test_f1,\n",
        "        \"test_acc\": test_acc,\n",
        "        \"pca_components\": n_components_used,\n",
        "        \"explained_variance\": explained_variance\n",
        "    }\n",
        "    \n",
        "    # Save model\n",
        "    model_path = models_dir / f\"{name}.pkl\"\n",
        "    joblib.dump(pipeline, model_path)\n",
        "    print(f\"  ‚úì Model saved to {model_path}\")\n",
        "    \n",
        "    # Log to MLflow if configured\n",
        "    if MLFLOW_TRACKING_URI:\n",
        "        with mlflow.start_run(run_name=name):\n",
        "            mlflow.log_param(\"model\", name.split(\"_\")[0])\n",
        "            mlflow.log_param(\"uses_pca\", True)\n",
        "            mlflow.log_param(\"uses_optuna\", False)\n",
        "            mlflow.log_param(\"pca_components\", n_components_used)\n",
        "            mlflow.log_param(\"explained_variance\", explained_variance)\n",
        "            mlflow.log_metric(\"cv_f1\", cv_f1)\n",
        "            mlflow.log_metric(\"test_f1\", test_f1)\n",
        "            mlflow.log_metric(\"test_accuracy\", test_acc)\n",
        "            \n",
        "            signature = infer_signature(X_train, pipeline.predict(X_train))\n",
        "            mlflow.sklearn.log_model(pipeline, \"model\", signature=signature)\n",
        "        print(f\"  ‚úì Logged to MLflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "GLOBAL BEST MODEL (WITHOUT OPTUNA)\n",
            "================================================================================\n",
            "Best model: randomforest_no_optuna\n",
            "CV F1:      0.9822\n",
            "Test F1:    1.0000\n",
            "Test Acc:   1.0000\n",
            "\n",
            "‚úì Saved best model to /Users/kusumareddy/python_final/models/global_best_model.pkl\n",
            "\n",
            "================================================================================\n",
            "SUMMARY OF ALL 8 EXPERIMENTS (WITHOUT OPTUNA)\n",
            "================================================================================\n",
            "Model                                    | CV F1    | Test F1  | Test Acc\n",
            "--------------------------------------------------------------------------------\n",
            "randomforest_no_optuna                   | 0.9822   | 1.0000   | 1.0000\n",
            "xgboost_no_optuna                        | 0.9859   | 1.0000   | 1.0000\n",
            "randomforest_with_pca_no_optuna          | 0.9811   | 1.0000   | 1.0000\n",
            "xgboost_with_pca_no_optuna               | 0.9822   | 1.0000   | 1.0000\n",
            "svm_no_optuna                            | 0.9166   | 0.9296   | 0.9268\n",
            "svm_with_pca_no_optuna                   | 0.9121   | 0.9252   | 0.9220\n",
            "logistic_no_optuna                       | 0.8548   | 0.8312   | 0.8098\n",
            "logistic_with_pca_no_optuna              | 0.8524   | 0.8312   | 0.8098\n",
            "\n",
            "‚úì Total time: 16 min 43.7 sec\n",
            "\n",
            "‚úÖ All 8 experiments complete! Check Dagshub for tracking.\n"
          ]
        }
      ],
      "source": [
        "# Combine all results\n",
        "all_results = {**results_no_pca, **results_with_pca}\n",
        "\n",
        "# Find global best model\n",
        "global_best_name = max(all_results, key=lambda k: all_results[k][\"test_f1\"])\n",
        "global_best = all_results[global_best_name]\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GLOBAL BEST MODEL (WITHOUT OPTUNA)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Best model: {global_best_name}\")\n",
        "print(f\"CV F1:      {global_best['cv_f1']:.4f}\")\n",
        "print(f\"Test F1:    {global_best['test_f1']:.4f}\")\n",
        "print(f\"Test Acc:   {global_best['test_acc']:.4f}\")\n",
        "\n",
        "# Save best model\n",
        "best_model_path = models_dir / \"global_best_model.pkl\"\n",
        "joblib.dump(global_best[\"pipeline\"], best_model_path)\n",
        "print(f\"\\n‚úì Saved best model to {best_model_path}\")\n",
        "\n",
        "# Print summary table\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY OF ALL 8 EXPERIMENTS (WITHOUT OPTUNA)\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Model':<40} | {'CV F1':<8} | {'Test F1':<8} | {'Test Acc':<8}\")\n",
        "print(\"-\" * 80)\n",
        "for name, res in sorted(all_results.items(), key=lambda x: -x[1][\"test_f1\"]):\n",
        "    print(f\"{name:<40} | {res['cv_f1']:.4f}   | {res['test_f1']:.4f}   | {res['test_acc']:.4f}\")\n",
        "\n",
        "end_time = time.monotonic()\n",
        "elapsed = end_time - start_time\n",
        "print(f\"\\n‚úì Total time: {int(elapsed//60)} min {elapsed%60:.1f} sec\")\n",
        "print(\"\\n‚úÖ All 8 experiments complete! Check Dagshub for tracking.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
